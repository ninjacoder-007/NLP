{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What are Corpora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting. Its plural is corpora. They can be derived in different ways like text that was originally electronic, transcripts of spoken language and optical character recognition, etc. A corpus is a collection of authentic text or audio organized into datasets. 'Authentic' in this case means text written or audio spoken by a native of the language or dialect. In natural language processing, a corpus contains text and speech data that can be used to train AI and machine learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e968f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are Tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f873df",
   "metadata": {},
   "outputs": [],
   "source": [
    "The term \"token\" refers to the total number of words in a text, corpus etc, regardless of how often they are repeated. The term \"type\" refers to the number of distinct words in a text\n",
    "\n",
    "Tokenization is a common task in Natural Language Processing (NLP). ... Tokens are the building blocks of Natural Language. Tokenization is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What are Unigrams, Bigrams, Trigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A 1-gram (or unigram) is a one-word sequence. For the above sentence, the unigrams would simply be: “I”, “love”, “reading”, “blogs”, “about”, “data”, “science”, “on”, “Analytics”, “Vidhya”.\n",
    "\n",
    "A 2-gram (or bigram) is a two-word sequence of words, like “I love”, “love reading”, or “Analytics Vidhya”. And a 3-gram (or trigram) is a three-word sequence of words like “I love reading”, “about data science” or “on inblog”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. How to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45852081",
   "metadata": {},
   "outputs": [],
   "source": [
    "An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Explain Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cacd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemmatization is a linguistic term that means grouping together words with the same root or lemma but with different inflections or derivatives of meaning so they can be analyzed as one item. The aim is to take away inflectional suffixes and prefixes to bring out the word's dictionary form. Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words. For example, runs, running, ran are all forms of the word run, therefore run is the lemma of all these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Explain Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”. Stemming is an important part of the pipelining process in Natural language processing. The input to the stemmer is tokenized words. How do we get these tokenized words? Well, tokenization involves breaking down the document into different words. To know in detail about tokenization and its working refer the article :\n",
    "\n",
    "Some more example of stemming for root word \"like\" include: ->\"likes\"\n",
    "\n",
    "->\"liked\"\n",
    "\n",
    "->\"likely\"\n",
    "\n",
    "->\"liking\"\n",
    "\n",
    "Errors in Stemming: There are mainly two errors in stemming –\n",
    "\n",
    "over-stemming\n",
    "under-stemming\n",
    "Over-stemming occurs when two words are stemmed from the same root that are of different stems. Over-stemming can also be regarded as false-positives.\n",
    "\n",
    "Under-stemming occurs when two words are stemmed from the same root that are not of different stems. Under-stemming can be interpreted as false-negatives.\n",
    "\n",
    "Applications of stemming :\n",
    "\n",
    "Stemming is used in information retrieval systems like search engines.\n",
    "It is used to determine domain vocabularies in domain analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06019b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Explain Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a process of converting a sentence to forms – list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on. Default tagging is a basic step for the part-of-speech tagging. It is performed using the DefaultTagger class. The DefaultTagger class takes ‘tag’ as a single argument. NN is the tag for a singular noun. DefaultTagger is most useful when it gets to work with most common part-of-speech tag. that’s why a noun tag is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Explain Chunking or shallow parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunking is defined as the process of natural language processing used to identify parts of speech and short phrases present in a given sentence.\n",
    "\n",
    "Recalling our good old English grammar classes back in school, note that there are eight parts of speech namely the noun, verb, adjective, adverb, preposition, conjunction, pronoun, and interjection. Also, in the above definition of chunking, short phrases refer to the phrases formed by including any of these parts of speech.\n",
    "\n",
    "For example, chunking can be done to identify and thus group noun phrases or nouns alone, adjectives or adjective phrases, and so on. Consider the sentence below:\n",
    "\n",
    "“I had burgers and pastries for breakfast.”\n",
    "\n",
    "In this case, if we wish to group or chunk noun phrases, we will get “burgers”, “pastries” and “lunch” which are the nouns or noun groups of the sentence.\n",
    "\n",
    "Where is chunking used?\n",
    "Why would we want to learn something without knowing where it is widely used?! Looking at the applications discussed in this section of the blog will help you stay curious till the end!\n",
    "\n",
    "Chunking is used to get the required phrases from a given sentence. However, POS tagging can be used only to spot the parts of speech that every word of the sentence belongs to.\n",
    "\n",
    "When we have loads of descriptions or modifications around a particular word or the phrase of our interest, we use chunking to grab the required phrase alone, ignoring the rest around it. Hence, chunking paves a way to group the required phrases and exclude all the modifiers around them which are not necessary for our analysis. Summing up, chunking helps us extract the important words alone from lengthy descriptions. Thus, chunking is a step in information extraction.\n",
    "\n",
    "Interestingly, this process of chunking in NLP is extended to various other applications; for instance, to group fruits of a specific category, say, fruits rich in proteins as a group, fruits rich in vitamins as another group, and so on. Besides, chunking can also be used to group similar cars, say, cars supporting auto-gear into one group and the others which support manual gear into another chunk and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Explain Noun Phrase (NP) chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Noun phrase chunking deals with extracting the noun phrases from a sentence. While NP chunking is much simpler than parsing, it is still a challenging task to build a accurate and very efficient NP chunker. The importance of NP chunking derives from the fact that it is used in many applications. As we can see, NP-chunks are often smaller pieces than complete noun phrases. For example, the market for system-management software for Digital's hardware is a single noun phrase (containing two nested noun phrases), but it is captured in NP-chunks by the simpler chunk the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Explain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Named entity recognition (NER) — sometimes referred to as entity chunking, extraction, or identification — is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category. For example, an NER machine learning (ML) model might detect the word “super.AI” in a text and classify it as a “Company”.\n",
    "\n",
    "NER is a form of natural language processing (NLP), a subfield of artificial intelligence. NLP is concerned with computers processing and analyzing natural language, i.e., any language that has developed naturally, rather than artificially, such as with computer coding languages.\n",
    "\n",
    "How is NER used?\n",
    "NER is suited to any situation in which a high-level overview of a large quantity of text is helpful. With NER, you can, at a glance, understand the subject or theme of a body of text and quickly group texts based on their relevancy or similarity. Some notable NER use cases include:\n",
    "\n",
    "Human resources:\n",
    "Speed up the hiring process by summarizing applicants’ CVs; improve internal workflows by categorizing employee complaints and questions\n",
    "\n",
    "Customer support: Improve response times by categorizing user requests, complaints and questions and filtering by priority keywords\n",
    "\n",
    "Search and recommendation engines: Improve the speed and relevance of search results and recommendations by summarizing descriptive text,\n",
    "\n",
    "reviews, and discussions:\n",
    "\n",
    "Booking.com is a notable success story here\n",
    "\n",
    "Content classification:\n",
    "Surface content more easily and gain insights into trends by identifying the subjects and themes of blog posts and news articles\n",
    "\n",
    "Health care:\n",
    "Improve patient care standards and reduce workloads by extracting essential information from lab reports Roche is doing this with pathology and radiology reports\n",
    "\n",
    "Academia:\n",
    "Enable students and researchers to find relevant material faster by summarizing papers and archive material and highlighting key terms, topics, and themes The EU’s digital platform for cultural heritage, Europeana, is using NER to make historical newspapers searchable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
